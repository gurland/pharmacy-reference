{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing abstract summarization with pegasus\n",
    "# Deps:\n",
    "# - pytorch (pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cpu)\n",
    "# - pip install transformers\n",
    "# - pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tokenizer\n",
    "# tokenizer = PegasusTokenizer.from_pretrained(\"google/pegasus-xsum\")\n",
    "tokenizer = PegasusTokenizer.from_pretrained(\"google/pegasus-pubmed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "# model = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-xsum\")\n",
    "model = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-pubmed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example text\n",
    "text = \"\"\"\n",
    "Artificial neural networks (ANNs), usually simply called neural networks (NNs) or neural nets, are computing systems inspired by the biological neural networks that constitute animal brains. An ANN is based on a collection of connected units or nodes called artificial neurons, which loosely model the neurons in a biological brain. Each connection, like the synapses in a biological brain, can transmit a signal to other neurons. An artificial neuron receives signals then processes them and can signal neurons connected to it. The \"signal\" at a connection is a real number, and the output of each neuron is computed by some non-linear function of the sum of its inputs. The connections are called edges. Neurons and edges typically have a weight that adjusts as learning proceeds. The weight increases or decreases the strength of the signal at a connection. Neurons may have a threshold such that a signal is sent only if the aggregate signal crosses that threshold.\n",
    "\"\"\"\n",
    "\n",
    "pubmed_text = \"\"\"\n",
    "N-acetylcysteine (NAC), which is an acetylated cysteine compound, has aroused scientific interest for decades due to its important medical applications. It also represents a nutritional supplement in the human diet. NAC is a glutathione precursor and shows antioxidant and anti-inflammatory activities. In addition to the uses quoted in the literature, NAC may be considered helpful in therapies to counteract neurodegenerative and mental health diseases. Furthermore, this compound has been evaluated for its neuroprotective potential in the prevention of cognitive aging dementia. NAC is inexpensive, commercially available and no relevant side effects were observed after its administration. The purpose of this paper is to give an overview on the effects and applications of NAC in Parkinson's and Alzheimer's disorders and in neuropathic pain and stroke.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to tokens\n",
    "# tokens = tokenizer(text, truncation=True, padding=\"longest\", return_tensors=\"pt\")\n",
    "\n",
    "pubmed_tokens = tokenizer(pubmed_text, truncation=True, padding=\"longest\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[16882, 14849,  3296,   143, 45884,   116,   312,   832,   705,   568,\n",
       "         14849,  3296,   143, 21323,   116,   158,   132, 14849, 22902,   108,\n",
       "           127,  6506,   747,  2261,   141,   109,  7777, 14849,  3296,   120,\n",
       "         11190,  2517, 13666,   107,   983,   110, 45884,   117,   451,   124,\n",
       "           114,   949,   113,  2064,  2022,   132, 11406,   568,  4958, 21708,\n",
       "           108,   162, 20910,   861,   109, 21708,   115,   114,  7777,  2037,\n",
       "           107,  1547,  1654,   108,   172,   109, 67403,   116,   115,   114,\n",
       "          7777,  2037,   108,   137, 14108,   114,  3846,   112,   176, 21708,\n",
       "           107,   983,  4958, 61017,  7183,  6466,   237,  1994,   183,   111,\n",
       "           137,  3846, 21708,  2064,   112,   126,   107,   139,   198, 41480,\n",
       "           194,   134,   114,  1654,   117,   114,   440,   344,   108,   111,\n",
       "           109,  2940,   113,   276, 61017,   117, 31295,   141,   181,   609,\n",
       "           121, 29371,  1434,   113,   109,  5906,   113,   203, 12212,   107,\n",
       "           139,  3649,   127,   568,  5198,   107, 73682,   116,   111,  5198,\n",
       "          2222,   133,   114,  1050,   120, 29117,   130,   761,  8467,   107,\n",
       "           139,  1050,  3445,   132, 14719,   109,  1881,   113,   109,  3846,\n",
       "           134,   114,  1654,   107, 73682,   116,   218,   133,   114, 10238,\n",
       "           253,   120,   114,  3846,   117,  1406,   209,   175,   109,  9413,\n",
       "          3846, 16244,   120, 10238,   107,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 337k/2.28G [00:12<2:55:57, 215kB/s]"
     ]
    }
   ],
   "source": [
    "# tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The following `model_kwargs` are not used by the model: ['new_max_tokens'] (note: typos in the generate arguments will also show up in this list)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# summarize\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# summary = model.generate(**tokens)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m pubmed_summary \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpubmed_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_max_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/tmp/pharmacy-reference/text_summarizer_service/venv/lib64/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/dev/tmp/pharmacy-reference/text_summarizer_service/venv/lib64/python3.10/site-packages/transformers/generation_utils.py:1146\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, force_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, renormalize_logits, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, exponential_decay_length_penalty, **model_kwargs)\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    912\u001b[0m \n\u001b[1;32m    913\u001b[0m \u001b[39mGenerates sequences of token ids for models with a language modeling head. The method supports the following\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1143\u001b[0m \u001b[39m['Paris ist eines der dichtesten besiedelten Gebiete Europas.']\u001b[39;00m\n\u001b[1;32m   1144\u001b[0m \u001b[39m```\"\"\"\u001b[39;00m\n\u001b[1;32m   1145\u001b[0m \u001b[39m# 0. Validate model kwargs\u001b[39;00m\n\u001b[0;32m-> 1146\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_model_kwargs(model_kwargs\u001b[39m.\u001b[39;49mcopy())\n\u001b[1;32m   1148\u001b[0m \u001b[39m# 1. Set generation parameters if not already defined\u001b[39;00m\n\u001b[1;32m   1149\u001b[0m bos_token_id \u001b[39m=\u001b[39m bos_token_id \u001b[39mif\u001b[39;00m bos_token_id \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mbos_token_id\n",
      "File \u001b[0;32m~/dev/tmp/pharmacy-reference/text_summarizer_service/venv/lib64/python3.10/site-packages/transformers/generation_utils.py:861\u001b[0m, in \u001b[0;36mGenerationMixin._validate_model_kwargs\u001b[0;34m(self, model_kwargs)\u001b[0m\n\u001b[1;32m    858\u001b[0m         unused_model_args\u001b[39m.\u001b[39mappend(key)\n\u001b[1;32m    860\u001b[0m \u001b[39mif\u001b[39;00m unused_model_args:\n\u001b[0;32m--> 861\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    862\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe following `model_kwargs` are not used by the model: \u001b[39m\u001b[39m{\u001b[39;00munused_model_args\u001b[39m}\u001b[39;00m\u001b[39m (note: typos in the\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    863\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m generate arguments will also show up in this list)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    864\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: The following `model_kwargs` are not used by the model: ['new_max_tokens'] (note: typos in the generate arguments will also show up in this list)"
     ]
    }
   ],
   "source": [
    "# summarize\n",
    "# summary = model.generate(**tokens)\n",
    "\n",
    "pubmed_summary = model.generate(**pubmed_tokens, max_new_tokens=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[16882, 14849,  3296,   143, 45884,   116,   312,   832,   705,   568,\n",
       "          14849,  3296,   143, 21323,   116,   158,   132, 14849, 22902,   108,\n",
       "            127,  6506,   747,  2261,   141,   109,  7777, 14849,  3296,   120,\n",
       "          11190,  2517, 13666,   107,   983,   110, 45884,   117,   451,   124,\n",
       "            114,   949,   113,  2064,  2022,   132, 11406,   568,  4958, 21708,\n",
       "            108,   162, 20910,   861,   109, 21708,   115,   114,  7777,  2037,\n",
       "            107,  1547,  1654,   108,   172,   109, 67403,   116,   115,   114,\n",
       "           7777,  2037,   108,   137, 14108,   114,  3846,   112,   176, 21708,\n",
       "            107,   983,  4958, 61017,  7183,  6466,   237,  1994,   183,   111,\n",
       "            137,  3846, 21708,  2064,   112,   126,   107,   139,   198, 41480,\n",
       "            194,   134,   114,  1654,   117,   114,   440,   344,   108,   111,\n",
       "            109,  2940,   113,   276, 61017,   117, 31295,   141,   181,   609,\n",
       "            121, 29371,  1434,   113,   109,  5906,   113,   203, 12212,   107,\n",
       "            139,  3649,   127,   568,  5198,   107, 73682,   116,   111,  5198,\n",
       "           2222,   133,   114,  1050,   120, 29117,   130,   761,  8467,   107,\n",
       "            139,  1050,  3445,   132, 14719,   109,  1881,   113,   109,  3846,\n",
       "            134,   114,  1654,   107, 73682,   116,   218,   133,   114, 10238,\n",
       "            253,   120,   114,  3846,   117,  1406,   209,   175,   109,  9413,\n",
       "           3846, 16244,   120, 10238,   107,     1]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# {**tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0, 16882, 14849,  3296,   143, 45884,   116,   158,   127,  6506,\n",
       "           747,  2261,   141,   109,  7777, 14849,  3296,   120, 11190,  2517,\n",
       "         13666,   107, 16882, 14849,  3296,   143, 45884,   116,   312,   832,\n",
       "           705,   568, 14849,  3296,   143, 21323,   116,   158,   132, 14849,\n",
       "         22902,   108,   127,  6506,   747,  2261,   141,   109,  7777, 14849,\n",
       "          3296,   120, 11190,  2517, 13666,   107,     1]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Artificial neural networks (ANNs) are computing systems inspired by the biological neural networks that constitute animal brains. Artificial neural networks (ANNs), usually simply called neural networks (NNs) or neural nets, are computing systems inspired by the biological neural networks that constitute animal brains.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizer.decode(summary[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aim : the purpose of this paper is to give an overview on effects and applications of acetylcysteine ( cysteine ) in pain and stroke disorders and neuropathic pain and stroke.methods: the acetylcysteine ( cysteine ), which is an acetylated compound, has aroused scientific interest for its medical applications.results:the acetylcysteine ( cysteine ), which is an acetylated compound, has aroused scientific interest for its medical applications.conclusions:the acetylcysteine ( cysteine ), which is an acetylated compound, has aroused scientific interest for its medical applications. <n> this paper gives an overview on effects and applications of acetylcysteine ( cysteine ) in pain and stroke disorders and neuropathic pain and stroke.conclusions:the acetylcysteine ( cysteine ), which is an acetylated compound, has aroused scientific interest for its medical applications. <n> this paper gives an overview on effects and applications of acetylcysteine ( cysteine ) in pain and stroke disorders and neuropathic pain and stroke.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(pubmed_summary[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "42bbe9452e50f3b6ad24d442f92958e6bcada4d48413aa5058f3fa7371574ea9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
